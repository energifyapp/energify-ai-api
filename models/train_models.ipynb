{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tensorflow.keras import Model\r\n",
    "from tensorflow.keras.layers import *\r\n",
    "import numpy as np\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# load datasets\r\n",
    "rooms_1 = pd.read_csv('../data/rooms_1.csv')\r\n",
    "rooms_1 = rooms_1.drop('Unnamed: 0', axis = 1)\r\n",
    "rooms_3 = pd.read_csv('../data/rooms_3.csv')\r\n",
    "rooms_3 = rooms_3.drop('Unnamed: 0', axis = 1)\r\n",
    "rooms_4 = pd.read_csv('../data/rooms_4.csv')\r\n",
    "rooms_4 = rooms_4.drop('Unnamed: 0', axis = 1)\r\n",
    "rooms_5 = pd.read_csv('../data/rooms_5.csv')\r\n",
    "rooms_5 = rooms_5.drop('Unnamed: 0', axis = 1)\r\n",
    "condo = pd.read_csv('../data/condo.csv')\r\n",
    "condo = condo.drop('Unnamed: 0', axis = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# separate between x and y\r\n",
    "x_1 = rooms_1['Previous Day']\r\n",
    "y_1 = rooms_1['Next day']\r\n",
    "x_3 = rooms_3['Previous Day']\r\n",
    "y_3 = rooms_3['Next day']\r\n",
    "x_4 = rooms_4['Previous Day']\r\n",
    "y_4 = rooms_4['Next day']\r\n",
    "x_5 = rooms_5['Previous Day']\r\n",
    "y_5 = rooms_5['Next day']\r\n",
    "x_condo = condo['Previous Day']\r\n",
    "y_condo = condo['Next day']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "# create baseline neural network\r\n",
    "class PredictionNet(Model):\r\n",
    "    def __init__(self, features_shape, name = None):\r\n",
    "        super(PredictionNet, self).__init__(name=name)\r\n",
    "        self.first_layer = Dense(features_shape*8, activation = 'relu')\r\n",
    "        self.second_layer = Dense(features_shape*4, activation = 'relu')\r\n",
    "        self.third_layer = Dense(features_shape*4, activation = 'relu')\r\n",
    "        self.final = Dense(1)\r\n",
    "    def call(self, x):\r\n",
    "        x = self.first_layer(x)\r\n",
    "        x = self.second_layer(x)\r\n",
    "        x = self.third_layer(x)\r\n",
    "        return self.final(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "test_model = PredictionNet(1, name = \"pred_net\")\r\n",
    "test_model.build((None, 1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "# create models for each dataset\r\n",
    "model_1 = PredictionNet(1, name = \"rooms_1\")\r\n",
    "model_1.build((None, 1))\r\n",
    "model_3 = PredictionNet(1, name = \"rooms_3\")\r\n",
    "model_3.build((None, 1))\r\n",
    "model_4 = PredictionNet(1, name = \"rooms_4\")\r\n",
    "model_4.build((None, 1))\r\n",
    "model_5 = PredictionNet(1, name = \"rooms_5\")\r\n",
    "model_5.build((None, 1))\r\n",
    "model_condo = PredictionNet(1, name = \"condo\")\r\n",
    "model_condo.build((None, 1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "# train the models\r\n",
    "model_1.compile(optimizer='adam', loss='mse', metrics=['mae'])\r\n",
    "model_3.compile(optimizer='adam', loss='mse', metrics=['mae'])\r\n",
    "model_4.compile(optimizer='adam', loss='mse', metrics=['mae'])\r\n",
    "model_5.compile(optimizer='adam', loss='mse', metrics=['mae'])\r\n",
    "model_condo.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "# train the models\r\n",
    "model_1.fit(x_1, y_1, validation_split = 0.2, batch_size = 8, epochs = 50, verbose = 0)\r\n",
    "model_3.fit(x_3, y_3, validation_split = 0.2, batch_size = 8, epochs = 50, verbose = 0)\r\n",
    "model_4.fit(x_4, y_4, validation_split = 0.2, batch_size = 8, epochs = 50, verbose = 0)\r\n",
    "model_5.fit(x_5, y_5, validation_split = 0.2, batch_size = 8, epochs = 50, verbose = 0)\r\n",
    "model_condo.fit(x_condo, y_condo, validation_split = 0.2, batch_size = 8, epochs = 50, verbose = 0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b564d8bba8>"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "# save the models\r\n",
    "model_1.save_weights('./model_1.h5')\r\n",
    "model_3.save_weights('./model_3.h5')\r\n",
    "model_4.save_weights('./model_4.h5')\r\n",
    "model_5.save_weights('./model_5.h5')\r\n",
    "model_condo.save_weights('./model_condo.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "4184fae79dc3a2c9f8f98935393294d886c9eccddd6835400bcbba68531bbfcb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}